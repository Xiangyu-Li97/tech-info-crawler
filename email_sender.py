'''
é‚®ä»¶å‘é€æ¨¡å—
'''
import json
import subprocess
from datetime import datetime

def load_latest_processed_data():
    """åŠ è½½æœ€æ–°çš„å¤„ç†åæ•°æ®"""
    import glob
    json_files = glob.glob("/home/ubuntu/tech_info_crawler/processed_data_*.json")
    if not json_files:
        print("æœªæ‰¾åˆ°å¤„ç†åçš„æ•°æ®æ–‡ä»¶")
        return None
    
    latest_file = sorted(json_files)[-1]
    print(f"æ­£åœ¨åŠ è½½: {latest_file}")
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    return data

def generate_markdown_report(data):
    """ç”ŸæˆMarkdownæ ¼å¼çš„å®Œæ•´æŠ¥å‘Š"""
    filename = f"/home/ubuntu/tech_info_crawler/daily_report_{datetime.now().strftime('%Y%m%d')}.md"
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("# ä¼˜è´¨ç§‘æŠ€ä¿¡æ¯æ—¥æŠ¥\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}\n\n")
        f.write(f"**æ€»æ–‡ç« æ•°**: {len(data)}\n\n")
        
        # æ•°æ®ç»Ÿè®¡
        f.write("## ğŸ“Š æ•°æ®ç»Ÿè®¡\n\n")
        
        # æŒ‰æ¥æºç»Ÿè®¡
        source_counts = {}
        for entry in data:
            source = entry['source']
            source_counts[source] = source_counts.get(source, 0) + 1
        
        f.write("### æŒ‰æ¥æºç»Ÿè®¡\n\n")
        for source, count in sorted(source_counts.items(), key=lambda x: x[1], reverse=True):
            f.write(f"- **{source}**: {count} ç¯‡\n")
        f.write("\n")
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        category_counts = {}
        for entry in data:
            for category in entry.get('categories', ['General']):
                category_counts[category] = category_counts.get(category, 0) + 1
        
        f.write("### æŒ‰åˆ†ç±»ç»Ÿè®¡\n\n")
        for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):
            f.write(f"- **{category}**: {count} ç¯‡\n")
        f.write("\n")
        
        f.write("---\n\n")
        
        # æŒ‰åˆ†ç±»å¯¼å‡º
        categories = ['AI', 'Biotech', 'Startup', 'VC']
        for category in categories:
            filtered = [entry for entry in data if category in entry.get('categories', [])]
            if filtered:
                f.write(f"## ğŸ”¥ {category} é¢†åŸŸ ({len(filtered)} ç¯‡)\n\n")
                for i, entry in enumerate(filtered[:20], 1):
                    f.write(f"### {i}. {entry['title']}\n\n")
                    f.write(f"- **æ¥æº**: {entry['source']}\n")
                    f.write(f"- **è¯„åˆ†**: {entry.get('quality_score', 0)}\n")
                    f.write(f"- **å‘å¸ƒæ—¶é—´**: {entry.get('published', 'N/A')}\n")
                    f.write(f"- **é“¾æ¥**: [{entry['link']}]({entry['link']})\n")
                    
                    # æ·»åŠ æ‘˜è¦(æˆªå–å‰300å­—ç¬¦)
                    summary = entry.get('summary', 'N/A')
                    if len(summary) > 300:
                        summary = summary[:300] + "..."
                    f.write(f"- **æ‘˜è¦**: {summary}\n\n")
                    f.write("---\n\n")
        
        # æ·»åŠ é¡µè„š
        f.write("\n---\n\n")
        f.write("*æœ¬æŠ¥å‘Šç”±ä¼˜è´¨ç§‘æŠ€ä¿¡æ¯çˆ¬å–ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*\n\n")
        f.write(f"*é¡¹ç›®åœ°å€*: [https://github.com/Xiangyu-Li97/tech-info-crawler](https://github.com/Xiangyu-Li97/tech-info-crawler)\n")
    
    print(f"MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")
    return filename

def send_email_via_mcp(to_email, subject, markdown_file):
    """é€šè¿‡MCPå·¥å…·å‘é€é‚®ä»¶"""
    print(f"æ­£åœ¨å‡†å¤‡å‘é€é‚®ä»¶åˆ°: {to_email}")
    
    # æ„å»ºé‚®ä»¶å†…å®¹
    content = f"æ‚¨å¥½ï¼\n\nè¿™æ˜¯ä»Šå¤©çš„ä¼˜è´¨ç§‘æŠ€ä¿¡æ¯æ—¥æŠ¥,è¯¦ç»†å†…å®¹è¯·æŸ¥çœ‹é™„ä»¶ä¸­çš„MarkdownæŠ¥å‘Šã€‚\n\n"
    content += f"æœ¬é‚®ä»¶ç”±ä¼˜è´¨ç§‘æŠ€ä¿¡æ¯çˆ¬å–ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆå¹¶å‘é€ã€‚\n"
    content += f"é¡¹ç›®åœ°å€: https://github.com/Xiangyu-Li97/tech-info-crawler\n"
    
    # åˆ›å»ºä¸´æ—¶JSONè¾“å…¥æ–‡ä»¶
    email_data = {
        "messages": [
            {
                "to": [to_email],
                "subject": subject,
                "content": content,
                "attachments": [markdown_file]
            }
        ]
    }
    
    temp_json = "/tmp/email_input_temp.json"
    with open(temp_json, 'w', encoding='utf-8') as f:
        json.dump(email_data, f, ensure_ascii=False, indent=2)
    
    # è°ƒç”¨MCPå·¥å…·å‘é€é‚®ä»¶
    try:
        result = subprocess.run(
            f'manus-mcp-cli tool call gmail_send_messages --server gmail --input "$(cat {temp_json})"',
            shell=True,
            capture_output=True,
            text=True,
            timeout=60
        )
        
        print("MCPå·¥å…·è¾“å‡º:")
        print(result.stdout)
        
        if result.returncode == 0 and "Message ID" in result.stdout:
            print("âœ… é‚®ä»¶å‘é€æˆåŠŸ!")
            return True
        else:
            print(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {result.stderr}")
            return False
    except subprocess.TimeoutExpired:
        print("âŒ é‚®ä»¶å‘é€è¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ é‚®ä»¶å‘é€å‡ºé”™: {e}")
        return False

def send_daily_report(to_email):
    """å‘é€æ¯æ—¥æŠ¥å‘Šçš„ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("å¼€å§‹ç”Ÿæˆå¹¶å‘é€æ¯æ—¥ç§‘æŠ€ä¿¡æ¯æŠ¥å‘Š")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    data = load_latest_processed_data()
    if not data:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®,æ— æ³•å‘é€æŠ¥å‘Š")
        return False
    
    # ç”ŸæˆMarkdownæŠ¥å‘Šé™„ä»¶
    markdown_file = generate_markdown_report(data)
    
    # å‘é€é‚®ä»¶
    subject = f"ä¼˜è´¨ç§‘æŠ€ä¿¡æ¯æ—¥æŠ¥ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}"
    success = send_email_via_mcp(to_email, subject, markdown_file)
    
    if success:
        print(f"\nâœ… æ¯æ—¥æŠ¥å‘Šå·²æˆåŠŸå‘é€åˆ°: {to_email}")
    else:
        print(f"\nâŒ æ¯æ—¥æŠ¥å‘Šå‘é€å¤±è´¥")
    
    return success

if __name__ == "__main__":
    # æµ‹è¯•é‚®ä»¶å‘é€ - è¯·æ›¿æ¢ä¸ºæ‚¨çš„é‚®ç®±åœ°å€
    send_daily_report("your-email@example.com")
